What are the Big-Oss of the following algorithm?

1.

def goodbye_world(n)
	puts "Adios World! #{n}"
end

Big-O = O(1). Only 1 element and 1 iteration necessary to run the algorithm. 

----------------------------------

2.

def find_largest(collection)
 largest = collection[0]
 collection.length.times do |i|
   if collection[i] >= largest
     largest = collection[i]
   end
 end
 largest
end

Big-O = O(collection.length) or O(n). The worst case scenario is that 'largest' is the last element in the collection; and the algorithm would need to iterate n times to return it. 

----------------------------------

3. 

def find_largest(collection)
 largest = collection[0][0]
 collection.length.times do |i|
   subcollection = collection[i]
   subcollection.length.times do |i|
     if subcollection[i] >= largest
       largest = subcollection[i]
     end
   end
 end
 largest
end

O(n). 2D doesn't matter this particular time, still iterates through each element.

----------------------------------

4. 

O(2^n). Exponential growth. 

----------------------------------

5. 

O(n log n). I ran the program multiple times in order to create this table:

n | f(n)

0 | 1
1 | 1
2 | 1
3 | 2
4 | 3
5 | 5
6 | 8
7 | 13
8 | 21
9 | 34
10| 55

These values don't match up exactly with the n log n values I googled, but they are closer to n log n than to any other Big-O complexity. 

----------------------------------

6. 

This one's interesting. After graphing the data, both the "unsorted" and "sorted/reverse" graphs appear to show linear growth. So I'd say the Big-O is O(n). However, the "unsorted" graph and the "sorted/reverse" graph are not identical. This makes me think that the best way to indicate the complexity is something like O(n+x), where "x" is a second variable representing a consistently growing "excess" of recursions. 

So, the short answer to this question is O(n), but the longer, more thorough answer is O(n+x). 